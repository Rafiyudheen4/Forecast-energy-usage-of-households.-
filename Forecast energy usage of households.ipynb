{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T16:44:28.845888Z",
     "start_time": "2018-06-28T16:44:28.839772Z"
    }
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:07.175109Z",
     "start_time": "2018-07-05T14:46:05.226256Z"
    },
    "cell_style": "center",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "headers = ['Date', 'Time', 'Global_active_power', 'Global_reactive_power',\n",
    "           'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "           'Sub_metering_3']\n",
    "\n",
    "dtypes = {'Date':'str', 'Time':'str', 'Global_active_power':'float',\n",
    "          'Global_reactive_power': 'float', 'Voltage':'float',\n",
    "          'Global_intensity':'float', 'Sub_metering_1':'float',\n",
    "          'Sub_metering_2':'float', 'Sub_metering_3':'float'}\n",
    "\n",
    "df = pd.read_csv('household_power_consumption.txt', sep=';',\n",
    "                 dtype=dtypes, na_values=['?'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the date and time fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:08.042691Z",
     "start_time": "2018-07-05T14:46:08.028394Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "def parallel_map(data, func):\n",
    "    n_cores = cpu_count()\n",
    "    data_split = np.array_split(data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def parse(row):\n",
    "    row['DateTime'] = pd.to_datetime(row['DateTime'],\n",
    "                                     format='%d/%m/%Y %H:%M:%S')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:15.796565Z",
     "start_time": "2018-07-05T14:46:09.311139Z"
    }
   },
   "outputs": [],
   "source": [
    "df['DateTime'] = df['Date'] + ' ' + df['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the original date and time fields and set the new DateTime field as index. Since the new field is of type datetime64[ns], setting it as index will change the type of the index to DateTimeIndex, which encapsulates the core of pandas support for time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:18.481040Z",
     "start_time": "2018-07-05T14:46:18.326858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16/12/2006 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/12/2006 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/12/2006 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/12/2006 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/12/2006 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "DateTime                                                                   \n",
       "16/12/2006 17:24:00                4.216                  0.418   234.84   \n",
       "16/12/2006 17:25:00                5.360                  0.436   233.63   \n",
       "16/12/2006 17:26:00                5.374                  0.498   233.29   \n",
       "16/12/2006 17:27:00                5.388                  0.502   233.74   \n",
       "16/12/2006 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "DateTime                                                                \n",
       "16/12/2006 17:24:00              18.4             0.0             1.0   \n",
       "16/12/2006 17:25:00              23.0             0.0             1.0   \n",
       "16/12/2006 17:26:00              23.0             0.0             2.0   \n",
       "16/12/2006 17:27:00              23.0             0.0             1.0   \n",
       "16/12/2006 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "DateTime                             \n",
       "16/12/2006 17:24:00            17.0  \n",
       "16/12/2006 17:25:00            16.0  \n",
       "16/12/2006 17:26:00            17.0  \n",
       "16/12/2006 17:27:00            17.0  \n",
       "16/12/2006 17:28:00            17.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "df = df[[df.columns[-1]] + list(df.columns[:-1])]\n",
    "df.set_index('DateTime', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data represents power consumption, it might make sense to engineer features such as day of week, month of year, and hour of day. These may provide information useful for predicting power consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:23.379761Z",
     "start_time": "2018-07-05T14:46:23.073206Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-99042afb3b0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'day_of_week'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdayofweek\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'hour'"
     ]
    }
   ],
   "source": [
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "df['day_of_week'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3 is given as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:25.662735Z",
     "start_time": "2018-07-05T14:46:25.598797Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Rest_active_power'] = df['Global_active_power'] * 1000 / 60 - \\\n",
    "                          df['Sub_metering_1'] - df['Sub_metering_2'] - \\\n",
    "                          df['Sub_metering_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is any missing data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:28.636346Z",
     "start_time": "2018-07-05T14:46:27.668133Z"
    }
   },
   "outputs": [],
   "source": [
    "number = len(df) - len(df.dropna())\n",
    "percentage = number * 100 / len(df)\n",
    "print(f'Number of points with missing values is: {number}')\n",
    "print(f'Percentage of points with missing values is: {percentage}\\n')\n",
    "print(f'Missing value counts:\\n{df.isnull().sum(axis=0)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:33.315988Z",
     "start_time": "2018-07-05T14:46:32.780452Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:48:23.436949Z",
     "start_time": "2018-07-05T12:48:23.009957Z"
    }
   },
   "source": [
    "It seems that much of the missing data is consecutive instances. Therefore, I wouldn't attempt to fill them. Instead, I will leave them as they are for now. They will be dropped later after transforming the data to a supervised setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of aggregated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aesthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:42.886164Z",
     "start_time": "2018-07-05T14:46:42.711343Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "my_fmt = mdates.DateFormatter('%a %d/%m %H:%M')\n",
    "\n",
    "# Tableau colors\n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),\n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),\n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),\n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),\n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n",
    "\n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]\n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global power consumption over the whole timespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average global active power over resampled data yearly, quarterly, monthly, and daily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:46.576022Z",
     "start_time": "2018-07-05T14:46:45.522605Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(22, 22))\n",
    "\n",
    "frequencies = ['1Y', '1M', '1Q', '1D']\n",
    "\n",
    "dic = {'1Y':'Yearly', '1M':'Monthly', '1Q':'Quarterly', '1D':'Daily'}\n",
    "\n",
    "i = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        for tick in col.get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "        col.plot(df[['Global_active_power']].resample(frequencies[i]).mean(),\n",
    "                 color=tableau20[i * 2])\n",
    "        col.set_xlabel('Time')\n",
    "        col.set_ylabel('Global Active Power (kW)')\n",
    "        col.set_title(dic[frequencies[i]])\n",
    "        col.xaxis.set_major_formatter(my_fmt)\n",
    "        \n",
    "        # Aesthetics\n",
    "        col.spines[\"top\"].set_visible(False)    \n",
    "        col.spines[\"right\"].set_visible(False)    \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can clearly see a quarterly seasonal trend in the data. Electricity consumption peaks in the winter and goes down in the summer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:12:49.725643Z",
     "start_time": "2018-06-28T18:12:49.720508Z"
    }
   },
   "source": [
    "## What happens on Sundays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:46:53.557062Z",
     "start_time": "2018-07-05T14:46:53.177335Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = plt.axes()\n",
    "\n",
    "# How many minutes in a week?\n",
    "week = 60 * 24 * 7\n",
    "\n",
    "columns = ['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3', 'Rest_active_power']\n",
    "names = ['Kitchen', 'Laundry Room', 'Electric Water Heater & Air Conditioner', 'Rest']\n",
    "\n",
    "d = {key:value for (key, value) in zip(columns, names)}\n",
    "\n",
    "for i in range(4):\n",
    "    plt.plot(df[[columns[i]]][week * 11:week * 11 + 2000], color=tableau20[i * 2])\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Power (W)')\n",
    "ax.set_title('Sub-meters')\n",
    "ax.xaxis.set_major_formatter(my_fmt)\n",
    "\n",
    "# Aesthetics\n",
    "ax.spines[\"top\"].set_visible(False)    \n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.legend(list(map(lambda x:d[x], columns)))\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things get crazy Sunday evening!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to create a model that forecasts power consumption is by formulating the forecasting problem as a supervised learning problem. I formulate the problem as follows: predict global active power at time $t + h$ given all the variables at times $t, t-1, ..., t-w$, where $h$ is the prediction horizon and $w$ is the window size. Here's a function that takes as input a time series dataframe, a window size, a horizon, a set of variables to be lagged and a set of variables to be forecasted and outputs the dataframe transformed and ready for supervised learing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:47:14.966033Z",
     "start_time": "2018-07-05T14:47:14.947508Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, window_size=1, horizon=1, inputs='all', targets='all'):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        data: A pandas DataFrame containing the time series\n",
    "        (the index must be a DateTimeIndex).\n",
    "        window_size: Number of lagged observations as input.\n",
    "        horizon: Number of steps to forecast ahead.\n",
    "        inputs: A list of the columns of the dataframe to be lagged.\n",
    "        targets: A list of the columns of the dataframe to be forecasted.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    if targets == 'all':\n",
    "        targets = data.columns\n",
    "    \n",
    "    if inputs == 'all':\n",
    "        inputs = data.columns\n",
    "\n",
    "    \n",
    "    result = DataFrame(index=df.index)\n",
    "    names = []\n",
    "    \n",
    "    # input sequence (t-w, ..., t-1)\n",
    "    for i in range(window_size, 0, -1):\n",
    "        result = pd.concat([result, data[inputs].shift(i)], axis=1)\n",
    "        names += [(f'{data[inputs].columns[j]}(t-{i})') for j in range(len(inputs))]\n",
    "    \n",
    "    # the input not shifted (t)\n",
    "    result = pd.concat([result, data.copy()], axis=1)\n",
    "    names += [(f'{column}(t)') for column in data.columns]\n",
    "    \n",
    "    # forecast (t+h)\n",
    "    for i in [horizon]:\n",
    "        result = pd.concat([result, data[targets].shift(-i)], axis=1)\n",
    "        names += [(f'{data[targets].columns[j]}(t+{i})') for j in range(len(targets))]\n",
    "    \n",
    "    # put it all together\n",
    "    result.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    result.dropna(inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if this works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:47:28.154685Z",
     "start_time": "2018-07-05T14:47:17.728283Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "inputs = ['Global_active_power', 'Global_reactive_power', 'Voltage',\n",
    "          'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "          'Sub_metering_3', 'Rest_active_power']\n",
    "\n",
    "targets = ['Global_active_power']\n",
    "\n",
    "df_supervised = series_to_supervised(df, window_size=5, horizon=1, inputs=inputs, targets=targets)\n",
    "df_supervised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. We can now start applying supervised machine learning algorithms to this dataset. There are multiple variables that could be interesting to study like how changing the windows size for a fixed forecasting horizon affects forecast quality, how forecast quality deteriorates as the forecasting horizon grows, and whether resampling and attempting to forecast on larger time steps works.\n",
    "\n",
    "One can devise a large scale experiment where multiple supervised learning datasets are generated with different window sizes, horizons and step sizes. A supervised machine learning algorithm would be applied on each of them and results could be stored and later nicely visualized.\n",
    "\n",
    "For now I'm going to stick with a window size of 5, a horizon of 1 and the default time step of 1 minute. I'll save the dataframe to a file, so I can restart the kernel to free some memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:49:30.129390Z",
     "start_time": "2018-07-05T14:47:50.998610Z"
    }
   },
   "outputs": [],
   "source": [
    "df_supervised.to_csv('supervised_w10_h1.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:55:02.817712Z",
     "start_time": "2018-07-05T14:54:41.915655Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_supervised = pd.read_csv('supervised_w10_h1.csv', parse_dates=['DateTime'])\n",
    "df_supervised.set_index('DateTime', inplace=True)\n",
    "df_supervised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:15:19.677661Z",
     "start_time": "2018-07-05T15:15:19.672201Z"
    }
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is split into training, validation and test sets without shuffling. I am not certain about whether shuffling would be wrong in this case, but I don't shuffle just to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:55:09.241966Z",
     "start_time": "2018-07-05T14:55:08.984179Z"
    }
   },
   "outputs": [],
   "source": [
    "percentages = (0.6, 0.2, 0.2)\n",
    "\n",
    "split_points = (int(len(df_supervised) * percentages[0]),\n",
    "                int(len(df_supervised) * (percentages[0] + percentages[1])))\n",
    "\n",
    "train, validate, test = df_supervised.iloc[:split_points[0]].copy(), \\\n",
    "                        df_supervised.iloc[split_points[0]:split_points[1]].copy(), \\\n",
    "                        df_supervised.iloc[split_points[1]:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T14:55:27.662120Z",
     "start_time": "2018-07-05T14:55:26.811542Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.values[:, :-1]\n",
    "y_train = train.values[:, -1]\n",
    "\n",
    "X_validate = validate.values[:, :-1]\n",
    "y_validate = validate.values[:, -1]\n",
    "\n",
    "X_test = test.values[:, :-1]\n",
    "y_test = test.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive baseline model: power consumption at time $t + 1$ is the same as power consumption at time $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:07:06.611404Z",
     "start_time": "2018-07-05T15:07:06.603148Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(validate['Global_active_power(t+1)'], validate['Global_active_power(t)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not-so-naive-but-still-naive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:07:31.861768Z",
     "start_time": "2018-07-05T15:07:24.414390Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:07:50.295880Z",
     "start_time": "2018-07-05T15:07:50.284899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(predictions, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:09:46.757577Z",
     "start_time": "2018-07-05T15:09:44.509797Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:10:05.444982Z",
     "start_time": "2018-07-05T15:10:05.403673Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Reshape, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:11:04.498304Z",
     "start_time": "2018-07-05T15:10:23.684814Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001))\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_validate, y_validate),\n",
    "                    callbacks=[EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:11:27.850181Z",
     "start_time": "2018-07-05T15:11:22.596956Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:11:46.084716Z",
     "start_time": "2018-07-05T15:11:46.076703Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_squared_error(predictions, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is significantly better than the baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:12:10.195767Z",
     "start_time": "2018-07-05T15:12:04.648624Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:12:28.691097Z",
     "start_time": "2018-07-05T15:12:28.677193Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot = test[['Global_active_power(t+1)']].copy()\n",
    "df_to_plot['Global_active_power(t+1)_predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T15:12:48.172219Z",
     "start_time": "2018-07-05T15:12:47.980763Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "df_to_plot[:1000].plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "365px",
    "left": "441px",
    "right": "647px",
    "top": "298px",
    "width": "765px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
